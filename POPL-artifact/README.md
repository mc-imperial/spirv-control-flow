# Artifact for "Taking Back Control in an Intermediate Representation for GPU Computing"

## Recommended platform
We have prepared and tested this artifact on Ubuntu 20.04 and Ubuntu 20.10. We recommend that you run the artifact using the same versions. Other Linux distributions should work too, although you may have to change some installation commands to suit your distribution. 

## Files included in the artifact

The main files you will need to download to investigate the artifact are as follows:

* `README.md` - this readme file
* `docker-image.tar.gz` - a Docker image
* `SPIRV-1.0r12.pdf`: the SPIR-V 1.0 specification, revision 12
* `SPIRV-1.6r1.pdf`: the SPIR-V 1.6 specification, revision 1 (featuring the latest versions of definitions before our changes were accepted)
* `SPIRV-1.6r2.pdf`: the SPIR-V 1.6 specification, revision 2 (incorporating our changes)
* `StructuredDominanceCFG.als`: our Alloy model
* `org.alloytools.alloy.dist.jar`: JAR distribution of Alloy (for Linux)
* `alloy.dmg`: DMG distribution of Alloy (for Mac - provided for convenience and completeness, though we recommend you try the artifact under Linux)
* `Bugs.ods`: A spreadsheet summarising the status of the bugs found by our fleshing technique

For completeness we have also made available the archives of test cases discussed in Tables 1 and 3 of the paper. However, these do *not* need to be downloaded in order to follow the steps below.

* `Tests-Basic-CTS.tar.gz`: The "Basic CTS" set (Table 1)
* `Tests-Basic-Alloy.tar.gz`: The "Basic Alloy" set (Table 1)
* `Tests-Phi-CTS.tar.gz`:  The "Phi CTS" set (Table 1)
* `Tests-Phi-Alloy.tar.gz`: The "Phi Alloy" set (Table 1)
* `Tests-Throughput.tar.gz`: The tests used for throughput testing (Table 3)

## List of claims

The artifact provides evidence to back up the following claims made in the paper. For each claim, we briefly summarise how the artifact provides supporting evidence.

- **Claim 1:** The SPIR-V specification has been updated to incorporate our notion of structural dominance and related rules.
**Evidence:** We provide PDF copies of the SPIR-V specification before and after our changes, and point out key places where our changes have been applied to the specification.
- **Claim 2:** These definitions and rules are based on a formal model of SPIR-V control flow. expressed in the Alloy modelling language.
**Evidence:** We provide an Alloy file containing our formal model, and walk through some example definitions from this model, showing how they relate to the SPIR-V specification document.
- **Claim 3:** Our Alloy model can be used together with the Alloy analyzer to generate both valid and invalid SPIR-V examples.
**Evidence:** We show how to use our formal model inside the Alloy Analyzer GUI to generate valid and invalid examples.
- **Claim 4:** Alloy performance decreases with the size of the generated CFG (table 3 in paper)
  **Evidence:** We provide a script that demonstrates this.
- **Claim 5:** Our alloy-to-spirv tool facilitates obtaining SPIR-V binary programs from examples generated by our Alloy model. These examples can then be cross-validated using the Khronos validation tool, spirv-val.
**Evidence:** Our Docker image contains the Python sources for alloy-to-spirv and instructions on how to use the tool. We give a worked example using the tool to confirm that spirv-val agrees with our model on the validity status of some examples.
- **Claim 6:** Our spirv-to-alloy tool facilitates obtaining inputs to our Alloy model from SPIR-V examples. 
**Evidence:** Via a Docker image, we provide the source code for spirv-to-alloy, instructions on how to build it from source, and a pre-built binary for the tool. We also provide a worked example on how to use spirv-to-alloy.
- **Claim 7:** spirv-to-alloy allows SPIR-V test cases from the Vulkan Conformance Test Suite to be validated against our Alloy model.
**Evidence:** Our Docker image shows how to scrape examples from the Vulkan test suite and convert them to Alloy using spirv-to-alloy.
- **Claim 8:** We have designed a tool chain implementing our novel control flow graph fleshing technique, to yield executable SPIR-V programs embedded in Amber test cases.
**Evidence:** Our Docker image contains the Python sources associated with our control flow graph fleshing implementation, and instructions for how to use the fleshing tooling in practice.
- **Claim 9:** Fleshing has led to the discovery of a number of SPIR-V compiler bugs.
**Evidence:** Our Docker image includes a build of SwiftShader, a software renderer for Vulkan. This allows us to demonstrate a number of the bugs found by our technique without requiring access to specific GPU hardware. We also provide a spreadsheet with links to the various bugs that we have reported to open source projects.

## Download, installation, and sanity-testing

Before going further, please try the following steps and check that they work. At this point we do not explain the purpose of the steps; we merely want to make sure that your system is compatible with the detailed instructions that follow.

### Get required packages

1. Install Java 8: `sudo apt install openjdk-8-jdk`
2. Check Java version: `java -version`, If your java version is not Java 8, then update your default version: `sudo update-alternatives --config java`
3. Install Docker: `sudo apt install docker.io`

### Check that the Alloy Analyzer GUI works

Validating some of our claims require using the Alloy Analyzer GUI, which you will need to download.

#### Check that the Analyzer installs

On Linux, download the `org.alloytools.alloy.dist.jar` file provided with the artifact, and either double-click to open is, or run the following command from the console:

`java -jar org.alloytools.alloy.dist.jar`

If on Mac OS X, download and open the `alloy.dmg` file available as part of the artifact. 

#### Check that the analyser works

Load the Alloy model provided with the artifact by selecting `File` > `Open` in top toolbar, and in the dialog that opens, browse to and select the `StructuredDominanceCFG.als`-file.
Click `Execute` in top toolbar and select `Run run$1 for exactly 8 Block`. Alloy Analyser will look for a matching example of the spec and will respond with “Instance found”. Click the `Show` button from the toolbar, and a new window will open up (the Alloy Visualizer) with a solution diagram similar to this:

![](https://i.imgur.com/vCYUBWc.png)

Export the visualised solution to an XML by going to `File` > `Export To` > `XML...` from the Vizualiser's Menu Bar.

### Download and check that the Docker image works
We provide a docker image that has all the necessary software pre-installed. This includes the tools produced by us for the paper and this artifact. If you would like to verify that this code builds from scratch, instructions for doing this can be found in the README of the repository provided in the docker image (/data/git/spirv-control-flow/README.md). Most of the code is in Python, so you will only need to build the spirv-to-alloy tool. 

For now, let's download the image, check that it can be loaded and run some basic checks to make sure that it works as expected.

0. Download the docker image (docker-image.tar.gz).

1. Load the docker image
``` 
sudo docker load -i /path/to/docker-image.tar.gz 
```

2. Get a shell in the docker image:
``` 
sudo docker run -it --entrypoint /bin/bash popl-artifact-final
```

3. Test that Amber and SwiftShader work:
```
/data/git/amber/out/Debug/amber -V
```
You should see the following output:
```
Amber        : e754c90
SPIRV-Tools  : a73e7243
SPIRV-Headers: b42ba6d
GLSLang      : 81cc10a4
Shaderc      : e72186b

Physical device properties:
  apiVersion: 1.2.0
  driverVersion: 20971520
  vendorID: 6880
  deviceID: 49374
  deviceType: cpu
  deviceName: SwiftShader Device (LLVM 10.0.0)
  driverName: SwiftShader driver
  driverInfo: 
  minSubgroupSize: 4
  maxSubgroupSize: 4
  maxComputeWorkgroupSubgroups: 64
  requiredSubgroupSizeStages: vert, frag, comp
End of physical device properties.

Summary: 0 pass, 0 fail
```

4. Check Python works:` python3 -V` should output ` Python 3.8.10`

5. Check that Alloy* works:
```
cd /data/git/spirv-control-flow
mkdir -p fleshing/test_sets/alloy/xml
java -classpath /data/git/alloystar -Xmx3g -Djava.library.path=/data/git/alloystar/amd64-linux -Dout=fleshing/test_sets/alloy/xml -Dquiet=false -Dsolver=minisat -Dhigherorder=true -Dcmd=0 -Diter=false  edu/mit/csail/sdg/alloy4whole/RunAlloy AlloyModel/StructuredDominanceCFG.als
```
You should see output similar to:
```
Running Alloy, using MiniSat on command 0.
11:44:23: Translation took 2.31s (224521 vars, 432 primary vars, 737481 clauses).
Solving took 3.63s.
11:44:26: Solution saved to fleshing/test_sets/alloy/xml/test_0.xml.
```

To exit the container, type `exit`.

## The updated SPIR-V specification (Claim 1)

In Sections 2 and 3 of the paper we quote from Version 1.6 revision 1 of the SPIR-V specification when discussing problematic definitions and rules. These quotations can be cross-checked against a copy of that specification version, **TODO Zenodo link**, provided with the artifact.

In Section 4 of the paper we claim that our revised definitions and rules have been incorporated into a more recent revision of the SPIR-V specification. This can be checked against Version 1.6 revision 2 of the specification, **TODO Zenodo link**, provided with the artifact.

[TODO] Ally to be a bit more concrete.

## Our Alloy model and its relationship to the specification (Claim 2)

[TODO] Ally: once Vasilis has revised this, go through and give page numbers in the SPIR-V PDFs.


The file `StructuredDominanceCFG.als` in the root of the artifact contains the Alloy model.
To give an insight into how the model’s axioms encode the SPIR-V spec’s ([SPIR-V 1.6r2](https://www.khronos.org/registry/SPIR-V/specs/unified1/SPIRV.html)) rules, we provide below few of our model’s 26 predicates that capture CFG validity constraints, all of which must hold for a CFG to be deemed valid. 



### Predicate 1 [line 586 in the model file]

```
pred LoopHeaderStructurallyDominatesContinueTarget
{
	let StructurallyReachableBlock = EntryBlock . *( branch . elems + merge + continue ) |
	StructurallyReachableBlock < : continue in structurallyDominates
}

```
This predicate encodes the requirement that every ([structurally reachable](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#StructurallyReachable)) [loop header](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#LoopHeader) in the CFG must [structurally dominate](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#StructurallyDominate) its continue-target [[SPIR-V 1.6r2, §2.11.1]](https://www.khronos.org/registry/SPIR-V/specs/unified1/SPIRV.html). It works in two steps. On the first line, it defines the set of [structurally reachable](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#StructurallyReachable) blocks as those that can be reached by starting at the `EntryBlock` and then taking zero or more steps, each of which is either a `branch`, `merge`, or `continue`. On the second line, the predicate constructs the set of pairs of blocks (*A*, *B*) where there is a continue-edge from *A* to *B* and *A* is in the set of [structurally reachable](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#StructurallyReachable) blocks (the `<:` syntax restricts the domain of a binary relation). The predicate requires that this set is a subset of (`in`) the structural dominance relation; that is, that *A* structurally dominates *B*. The control flow graph below depicts the `continue`-relation with the [loop header](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#LoopHeader) *A* structurally dominating the corresponding `continue` target *B*.

![](https://i.imgur.com/uFXdyH0.png)





### Predicate 2 [line 540 in the model file]

```
pred UniqueMergeBlock 
{
	all b : HeaderBlock & StructurallyReachableBlock | no b.merge & ((HeaderBlock & StructurallyReachableBlock) - b).merge
}
```
This predicate encodes the constraint that the merge block declared by a [header block](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#HeaderBlock) must not be a merge block declared by any other [header block](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#HeaderBlock) [[SPIR-V 1.6r2, §2.11.1]](https://www.khronos.org/registry/SPIR-V/specs/unified1/SPIRV.html). The predicate tells that for every [structurally reachable](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#StructurallyReachable) [header block](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#HeaderBlock) (`&` denotes intersection), e.g., *A* in the CFG above, its merge block, $mb1$, is different from any other [structurally reachable](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#StructurallyReachable) [header block](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#HeaderBlock)’s merge block $mb2$., i.e., $mb1 \cap mb2= \emptyset$.

### Predicate 3 [line 563 in the model file]

```
pred  BackEdgesBranchToLoopHeader 
{
	ran[backEdge] & StructurallyReachableBlock in LoopHeader & StructurallyReachableBlock 
}
pred OneBackEdgeBranchingToLoopHeader 
{
	all lh :LoopHeader & StructurallyReachableBlock  | one backEdge :> lh
}
```
The two predicates above embody the rule that all [back edges](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#BackEdge) must branch to a [loop header](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#LoopHeader) (encoded by the first predicate) with each [loop header](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#LoopHeader) having exactly one back edge branching to it (encoded by the second predicate) [[SPIR-V 1.6r2, §2.11.1]](https://www.khronos.org/registry/SPIR-V/specs/unified1/SPIRV.html). The first predicate specifies that every back-edge is pointing to a [structurally reachable](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#StructurallyReachable) [loop header](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#LoopHeader) (i.e., the range for the binary relation `backEdge`  is a subset of the set of all [structurally reachable](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#StructurallyReachable) [loop header](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#LoopHeader)s); the second predicate restricts the number of elements of `backEdge` that end with an element in `LoopHeader` to one.

### Predicate 4 [line 725 in the model file]

```
pred OpSwitchBlockDominatesAllItsCases 
{
   all sw: (SwitchBlock & StructurallyReachableBlock | (sw <: branch . elems:> ( StructurallyReachableBlock  - sw.merge)) in structurallyDominates
}
```
Here this predicate encodes the rule for structured control-flow constructs that for a switch construct *S* with associated [OpSwitch](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#OpSwitch) instruction, the [header block](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#HeaderBlock) for *S* must [structurally dominate](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#StructurallyDominate) every case construct associated with *S* [[SPIR-V 1.6r2, §2.11.3]](https://www.khronos.org/registry/SPIR-V/specs/unified1/SPIRV.html). The predicate constructs the set of pairs of blocks (*A*, *B*) where there is a branch-edge from *A* to *B* and *A* is in the set of [structurally reachable](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#StructurallyReachable)  [switch headers](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#SwitchHeader) the cases of which (the [OpSwitch](https://registry.khronos.org/SPIR-V/specs/unified1/SPIRV.html#OpSwitch) *Target* or *Default* blocks) are in *B*. The predicate requires that this set is a subset of the structural dominance relation; that is, that *A* structurally dominates *B*.
The figure below is an example of violation of the rule as the switch header 12 does not structurally dominate its case construct 11; it does not even dominate its case construct 10. 

![](https://i.imgur.com/W5BGgQG.png)

## Using our Alloy model to generate valid and invalid examples (Claim 3)



### Generating valid examples 

A naive approach for generating a valid example, i.e., one that conforms to all SPIR-V rules, using the Alloy model is to run the Alloy GUI Analyzer and under the `Execute` menu option select `Run Default`. The examples that will be generated using this approach, however, lack interesting stories; they may introduce minimal examples lacking vividness (for e.g., instances with low nesting level) or perhaps larger examples with repeating patterns -- all of them obeying the SPIR-V spec rules, by the way.

To patronise the Alloy Analyzer so that the generated examples are of more interest, we introduce new auxiliary constraints to the model which only cater for the shape of the example and the patterns of the constructs, all being orthogonal to the SPIR-V spec. The constraint below, for e.g., encodes three demands: 
1. the first part models the fact that there should not exist Blocks *A*, *B*, *C*, such that:
     * *B* is the only structural-successor of *A*
     * *A* is the only structural-predecessor of *B*
     * *C* is the only structural-successor of *B*
     * *B* is the only structural-predecessor of *C*  

    **_NOTE:_** The prefix operator # (cardinality) on a relation produces the relation's size.

2. the second part of the constraint instructs Alloy Analyzer to restrict the number of switch-cases to three;
3. on the last line, the constraint prevents parallel edges.

```
pred Vibrant 
{
	all disj A,B,C: Block | not (  #(A. (branchSet + merge + continue) - A) = 1 and B in A.(branchSet + merge + continue)  and 
					#(B.~(branchSet + merge + continue) - B) = 1 and A in B.~(branchSet + merge + continue) and
					#(B. (branchSet + merge + continue) - B) = 1 and C in B. (branchSet + merge + continue) and 
					#(C.~(branchSet + merge + continue) - C) = 1 and B in C.~(branchSet + merge + continue) 
										  )
	all sw: SwitchBlock | #(sw<:branch) <= 3

	all  a,b: Block | #(a<:branch:>b) < 2
}
```

To impose a deeper nesting level setup, we introduce another auxiliary predicate which doesn't allow two outmost constructs. The function `outerInner` defines which constructs are within the body of which other constructs.
```
pred MoreInteresting
{
	all disj h1,h2: HeaderBlock | some (h1+h2).~outerInner
	#LoopHeader > 0
}
```

Once the auxiliary contraints are added, it's time to generate valid instances of the model. By executing the `run`-command below (already included in the Alloy model), for e.g., the Alloy Analyzer will find possible examples (if any) for which all the predicates in the command are satisfiable within the scope used (`for exactly 8 Block`). The predicate `Valid` encodes all the SPIR-V rules, `Vibrant` and `MoreInteresting` rule out some boring patterns, while the rest predicates define the preferred number of the constructs in the examples.

```
run { Valid && Vibrant && MoreInteresting && #LoopHeader=1 && #(SelectionHeader-SwitchBlock)=1 && #SwitchBlock=1 } for exactly 8 Block
```
If an example is found, it can be visualised by clicking on the `Show` button (see below instance). The visualisations then can be written to an XML file (`File`/`Export to`). 

![](https://i.imgur.com/LOWpPLA.png)

We show below, under Claim 5, how to convert the generated Alloy example into SPIR-V assembly and cross check its validity using the official Khronos validator `spirv-val`.



### Generating invalid examples 

Generating invalid examples is easy; you can negate a subset of predicates from the super-predicate `Valid` (`Valid` is a conjunction over all SPIR-V rules) and then use exactly the same procedure as generating valid examples. Tweaking the `Valid` predicate in the alloy model file as below, will force the Alloy Analyzer to generate an example with a switch-block which does not structurally dominates all its cases. The visualisation of the generated example that follows the predicate, exhibits this behaviour (`SelectionHeader1` does not structurally dominate the case `Block3`). The validator is expected to reject this example.

<pre>
pred Valid { 
	UniqueMergeBlock 
	HeaderBlockStrictlyStructurallyDominatesItsMergeBlock 
	BackEdgesBranchToLoopHeader 
	OneBackEdgeBranchingToLoopHeader 
	LoopHeaderStructurallyDominatesContinueTarget 
	ContinueTargetStructurallyDominatesBackEdge 
	BackEdgeStructurallyPostDominatesContinueTarget 
	ConstructContainsAnotherHeader 
	ValidBreakBlock 
	ValidContinueBlock 
	ValidBranchToOuterOpSwitchMerge 
	InvalidBranchToOuterOpSwitchMerge 
	NobranchBetweenCaseConstructs 
	BranchesBetweenConstructs 
<span style="color:red;font-weight:700;font-size:15px">not OpSwitchBlockDominatesAllItsCases</span>
	AtMostOneBranchToAnotherCaseConstruct 
	CaseConstructBranchedToByAtMostOneOther 
	OrderOfOpSwitchTargetOperands
	EntryBlockIsNotTargeted 
	OpLoopMergeSecondToLast 
	OpSelectionMergeSecondToLast
	OutDegree 
	MultipleOutEdges 
	ExitingTheConstruct 
	StructurallyAcyclic
	BranchToContinue
}
</pre>

![](https://i.imgur.com/iaARtNK.png)

## Performance of Alloy in relation to CFG size (Claim 4)
From now on, you will need to be executing commands inside the docker container that we have provided. To get a shell in the container, run:
```
sudo docker run -it --entrypoint /bin/bash popl-artifact-final
```

[TODO] Take text from below about generating examples on command line and in bulk, and then extend it with performance stuff.

## The alloy-to-spirv tool (Claim 5)


### Running Alloy Analyzer from the Command Line


You may want to run Alloy from command-line in which case the Alloy* should be installed.  Note the absolute paths to the `Alloy*`

    **_NOTE:_** We use `Alloy*` just because it's a convenient way to get a command-line version of Alloy; we don't actually need its higher-order quantification abilities.

To generate a valid example on macOS run the following from the command line:

```
java -classpath </path/to/alloystar> -Xmx3g -Djava.library.path=</path/to/alloystar/processor_info> -Dout=</path/where/xml/output/is/written/to> -Dquiet=false -Dsolver=minisat -Dhigherorder=true -Dcmd=0 -Diter=false  edu/mit/csail/sdg/alloy4whole/RunAlloy </path/to/ally/model/StructuredDominanceCFG.als>
```
where processor_info is `amd64-linux` if the platform machine is AMD64"; `x86-linux` if 32-bit architecture linux; `x86-mac` if MacOS; `x86-windows` if win32 and `x86-freebsd` if platform is freebsd7.
The above command will search for the compiled version of the `edu/mit/csail/sdg/alloy4whole/RunAlloy` class and load it; next, it will call the main method passing the model file as argument. 
Note that the Alloy model provided in the Docker image contains already a `run`-command which will be executed upon invoking the Alloy Analyzer from Command Line. The solution will be saved as an XML-file to the folder passed as value of `Dout`, which must exist. 

The procedure for generating a valid example differs from generating invalid one in that in the latter case a subset of predicates from the `Valid` predicate in the model are negated, as described earlier. 

### Validating examples with the Khronos official validator. 

Use the following command:
```
./alloy-to-spirv/convert.py  <path_to_xml_file>   >   <path_to_asm_file>
```
to convert the generated Alloy example into SPIR-V assembly.

You can then assemble this SPIR-V and check its validity via (using the `spirv-as` and `spirv-val` binaries from the SPIRV-Tools folder:

```
spirv-as --target-env spv1.3 <path_to_asm_file>  -o  <path_to_spv_file> --preserve-numeric-ids

spirv-val <path_to_spv_file>
```
The assembler, `spirv-as`, reads the assembly language text, and emits the binary form on which operates the validator `spirv-val`. The validator is expected to agree with the Alloy model (i.e., deems the example as valid), otherwise a new bug has been found. 


### Generating examples in bulk

By changing the value of `Diter` to `true`, the analyser will iteratively generate all possible instances of the specification (saved as XML files); in this case timeout will come in handy allowing you to run the command with a time limit as follows: 

```
timeout <duration> java -classpath </path/to/alloystar> -Xmx3g -Djava.library.path=</path/to/alloystar/processor_info> -Dout=</path/where/xml/output/is/written/to> -Dquiet=false -Dsolver=minisat -Dhigherorder=true -Dcmd=0 -Diter=true  edu/mit/csail/sdg/alloy4whole/RunAlloy </path/to/alloy/model/StructuredDominanceCFG.als>
```
where 'duration' can be a positive integer or a floating-point number, followed by an optional unit suffix:

* s - seconds (default)
* m - minutes
* h - hours
* d - days

When no unit is used, it defaults to seconds. If the duration is set to zero, the associated timeout is disabled.
Running Alloy Analyzer in the terminal on a MacBook Pro i7-1068NG7, for e.g., for 20 seconds (using MiniSat as SAT solver), it generated 796 examples of 8 blocks; took 1,91s to translate the model into a Boolean formula whose satisfying assignments correspond to instances in the model; and the rest of the time was used by the SAT solver to solve the Boolean formula for all the instances. Recall that the scope (8) that bounds the size of the domains is defined in the `run`-command in the model file. The scope can be modified within reasonable limits; the larger the scope, the larger the search space and the slower the analysis will become (even intractable).
 



## The spirv-to-alloy tool (Claim 6)

[TODO] Once Vasilis has produced an example spirv file from an als file, write instructions for how to use spirv-to-alloy to convert it back to an als file.

## Converting Vulkan CTS test cases to Alloy using spirv-to-alloy (Claim 7)
One way of generating CFGs is to scrape them from the Vulkan conformance test suite (CTS). Running the commands below will scrape the Vulkan CTS and output Alloy (.als) files to the VulkanCTS directory. Each als file represents one scraped CFG.

``` 
cd /data/git/spirv-control-flow
python3 ./spirv-to-alloy/scrape-vulkan-cts.py VulkanCTS VulkanCTS /data/git/VK-GL-CTS/ /data/glslang/bin/glslangValidator /data/git/SPIRV-Tools/pre-built/tools/spirv-as /data/git/SPIRV-Tools/pre-built/tools/spirv-dis /data/git/spirv-control-flow/spirv-to-alloy/build/src/spirv_to_alloy/spirv-to-alloy
```

Once the als files are generated, we can check that they conform to our Alloy model (i.e. they are valid CFGs) and convert them to the XML representation that our fleshing tool can consume. To begin the validation and XML conversion process, run the following command:

```
python3 isCFGdeemedFeasible.py -a /data/git/spirv-control-flow/VulkanCTS -x /data/git/spirv-control-flow/fleshing/test_sets/vulkan_cts/xml -c /data/git/alloystar --block-limit 40
```

Running this command will take some time (1-2 hours) as Alloy must verify each CFG. If you just want to convert the CFGs into XML, then append the --skip-validation option to the above command and the process should take around 10-15 minutes. You should see output like the following:
```
423 GRAPHS WERE PROCESSED. 0 GRAPHS HAD ERRORS. 392 GRAPHS WERE CHECKED. 0 ARE INFEASIBLE. 31 WERE SKIPPED.
```

The 31 CFGs skipped have more than 40 blocks and would take a relatively long time to verify and convert, so they are skipped to keep the time needed for this example short. You can vary the block limit to see how it affects the verification and conversion time.

Once the process is complete, there should be directories containing xml files in the `./fleshing/test_sets/vulkan_cts/xml directory`.
## Control flow graph fleshing (Claim 8)

*Fleshing* is the process of turning a CFG skeleton into an exectuable program that will follow a predetermined path through that CFG. The fleshing/fleshout.py program is responsible for fleshing an individual CFG. It supports a number of options including:
1. Fleshing a single path executed by a single thread
2. Fleshing with op-phi instructions enabled
3. Fleshing multiple threads that follow independent paths

For the purpose of this explanation, ensure you are in the `/data/git/spirv-control/flow` directory. You should already have completed the Claim 7 section which generated CFG skeletons from the Vulkan CTS. We'll use the CFG in `./fleshing/test_sets/vulkan_cts/xml/s005/test_0.xml`.

### Fleshing a single path
To produce a basic fleshed test case that will have a single thread following a predetermined path, run:
```
python3 fleshing/fleshout.py ./fleshing/test_sets/vulkan_cts/xml/s005/test_0.xml --seed 1
```
This will output both the CFG skeleton as SPIR-V code, followed by the fully fleshed test case in the form of an amber program. An amber program is essentially the SPIR-V code generated by our fleshing tool, wrapped in amberscript code that handles the necessary scaffolding for setting up, executing and checking the results of SPIR-V programs. Below is the amber program generated:
```
#!amber
SHADER compute compute_shader SPIRV-ASM
; Follow the path(s):
; unique path #0: 8 -> 9 -> <10> -> 13

;
; 1 CFG nodes have OpBranchConditional or OpSwitch as their terminators (denoted <n>): 10.
;
; To follow these paths, we need to make decisions each time we reach 10.
; These paths were generated with the seed 1 and have lengths ranging from 4 to 4.
;
; We equip the shader with 1+1 storage buffers:
; - An input storage buffer with the directions for each node 10
; - An output storage buffer that records the blocks that are executed

; SPIR-V
; Version: 1.3
; Generator: Khronos Glslang Reference Front End; 8
; Bound: 15
; Schema: 0
               OpCapability Shader
               OpMemoryModel Logical GLSL450
               OpEntryPoint GLCompute %7 "main" %local_invocation_idx_var %workgroup_id_var
               OpExecutionMode %7 LocalSize 1 1 1
               
               ; Below, we declare various types and variables for storage buffers.
               ; These decorations tell SPIR-V that the types and variables relate to storage buffers

               OpDecorate %size_1_struct_type BufferBlock
               OpMemberDecorate %size_1_struct_type 0 Offset 0
               OpDecorate %size_1_array_type ArrayStride 4

               OpDecorate %output_struct_type BufferBlock
               OpMemberDecorate %output_struct_type 0 Offset 0
               OpDecorate %output_array_type ArrayStride 4

               OpDecorate %directions_10_variable DescriptorSet 0
               OpDecorate %directions_10_variable Binding 0

               OpDecorate %directions_10_index_variable DescriptorSet 0
               OpDecorate %directions_10_index_variable Binding 1

               OpDecorate %output_variable DescriptorSet 0
               OpDecorate %output_variable Binding 2

               OpDecorate %output_index_variable DescriptorSet 0
               OpDecorate %output_index_variable Binding 3

               OpDecorate %local_invocation_idx_var BuiltIn LocalInvocationIndex
               OpDecorate %workgroup_id_var BuiltIn WorkgroupId

          %1 = OpTypeVoid
          %2 = OpTypeFunction %1
          %3 = OpTypeBool
          %4 = OpTypeInt 32 0
          %5 = OpConstantTrue %3
          %6 = OpConstant %4 0

               %dummy_val = OpConstant %4 666
               %constant_17 = OpConstant %4 17
               %constant_14 = OpConstant %4 14
               %constant_13 = OpConstant %4 13
               %constant_1 = OpConstant %4 1
               %constant_0 = OpConstant %4 0
               %constant_15 = OpConstant %4 15
               %constant_16 = OpConstant %4 16
               %constant_11 = OpConstant %4 11
               %constant_2 = OpConstant %4 2
               %constant_10 = OpConstant %4 10
               %constant_9 = OpConstant %4 9
               %constant_5 = OpConstant %4 5
               %constant_12 = OpConstant %4 12
               %constant_8 = OpConstant %4 8

               ; Declaration of storage buffers for the 1 directions and the output

               %size_1_array_type = OpTypeArray %4 %constant_1
               %size_1_struct_type = OpTypeStruct %size_1_array_type
               %size_1_pointer_type = OpTypePointer Uniform %size_1_struct_type

               %directions_10_variable = OpVariable %size_1_pointer_type Uniform
               %directions_10_index_variable = OpVariable %size_1_pointer_type Uniform

               %output_array_type = OpTypeArray %4 %constant_5
               %output_struct_type = OpTypeStruct %output_array_type
               %output_pointer_type = OpTypePointer Uniform %output_struct_type
               %output_variable = OpVariable %output_pointer_type Uniform
               %output_index_variable = OpVariable %size_1_pointer_type Uniform

               %local_int_ptr = OpTypePointer Function %4
               %storage_buffer_int_ptr = OpTypePointer Uniform %4

               %input_int_ptr = OpTypePointer Input %4
               %local_invocation_idx_var = OpVariable %input_int_ptr Input
               %vec_3_input = OpTypeVector %4 3
               %workgroup_ptr = OpTypePointer Input %vec_3_input 
               %workgroup_id_var = OpVariable %workgroup_ptr Input

          %7 = OpFunction %1 None %2

          %8 = OpLabel ; validCFG/Block$6
               %output_index = OpVariable %local_int_ptr Function %constant_0
               %directions_10_index = OpVariable %local_int_ptr Function %constant_0

               %local_invocation_idx = OpLoad %4 %local_invocation_idx_var
               %x_wg_dim_ptr = OpAccessChain %input_int_ptr %workgroup_id_var %constant_0
               %y_wg_dim_ptr = OpAccessChain %input_int_ptr %workgroup_id_var %constant_1
               %z_wg_dim_ptr = OpAccessChain %input_int_ptr %workgroup_id_var %constant_2
               %x_wg_dim = OpLoad %4 %x_wg_dim_ptr
               %y_wg_dim = OpLoad %4 %y_wg_dim_ptr
               %z_wg_dim = OpLoad %4 %z_wg_dim_ptr
               %z_idx_component = OpIMul %4 %z_wg_dim %constant_1
               %y_idx_component = OpIMul %4 %y_wg_dim %constant_1
               %yz_idx_component = OpIAdd %4 %y_idx_component %z_idx_component
               %workgroup_idx = OpIAdd %4 %yz_idx_component %x_wg_dim

               %workgroup_offset = OpIMul %4 %workgroup_idx %constant_1
               %thread_index_offset = OpIAdd %4 %workgroup_offset %local_invocation_idx

               %directions_10_start_idx_ptr = OpAccessChain %storage_buffer_int_ptr %directions_10_index_variable %constant_0 %thread_index_offset
               %directions_10_offset = OpLoad %4 %directions_10_start_idx_ptr
               %output_start_idx_ptr = OpAccessChain %storage_buffer_int_ptr %output_index_variable %constant_0 %thread_index_offset
               %output_offset = OpLoad %4 %output_start_idx_ptr

               OpStore %directions_10_index %directions_10_offset
               OpStore %output_index %output_offset

   %temp_8_0 = OpLoad %4 %output_index
   %temp_8_1 = OpAccessChain %storage_buffer_int_ptr %output_variable %constant_0 %temp_8_0
               OpStore %temp_8_1 %constant_8
   %temp_8_2 = OpIAdd %4 %temp_8_0 %constant_1
               OpStore %output_index %temp_8_2
               OpBranch %9


          %9 = OpLabel ; validCFG/LoopHeader$0
   %temp_9_0 = OpLoad %4 %output_index
   %temp_9_1 = OpAccessChain %storage_buffer_int_ptr %output_variable %constant_0 %temp_9_0
               OpStore %temp_9_1 %constant_9
   %temp_9_2 = OpIAdd %4 %temp_9_0 %constant_1
               OpStore %output_index %temp_9_2
               OpLoopMerge %13 %17 None
               OpBranch %10


         %10 = OpLabel ; validCFG/Block$4
  %temp_10_0 = OpLoad %4 %output_index
  %temp_10_1 = OpAccessChain %storage_buffer_int_ptr %output_variable %constant_0 %temp_10_0
               OpStore %temp_10_1 %constant_10
  %temp_10_2 = OpIAdd %4 %temp_10_0 %constant_1
               OpStore %output_index %temp_10_2
  %temp_10_3 = OpLoad %4 %directions_10_index
  %temp_10_4 = OpAccessChain %storage_buffer_int_ptr %directions_10_variable %constant_0 %temp_10_3
  %temp_10_5 = OpLoad %4 %temp_10_4
  %temp_10_6 = OpIEqual %3 %temp_10_5 %constant_1
  %temp_10_7 = OpIAdd %4 %temp_10_3 %constant_1
               OpStore %directions_10_index %temp_10_7
               OpBranchConditional %temp_10_6 %11 %13


         %11 = OpLabel ; validCFG/SelectionHeader$1
               OpSelectionMerge %14 None
               OpBranchConditional %5 %12 %14


         %12 = OpLabel ; validCFG/Block$3
               OpReturn


         %14 = OpLabel ; validCFG/SelectionHeader$0
               OpSelectionMerge %16 None
               OpBranchConditional %5 %15 %16


         %15 = OpLabel ; validCFG/Block$2
               OpBranch %13


         %16 = OpLabel ; validCFG/Block$1
               OpBranch %17


         %13 = OpLabel ; validCFG/Block$5
  %temp_13_0 = OpLoad %4 %output_index
  %temp_13_1 = OpAccessChain %storage_buffer_int_ptr %output_variable %constant_0 %temp_13_0
               OpStore %temp_13_1 %constant_13
  %temp_13_2 = OpIAdd %4 %temp_13_0 %constant_2
               OpStore %output_index %temp_13_2
               OpReturn


         %17 = OpLabel ; validCFG/Block$0
               OpBranch %9

               OpFunctionEnd

 END

 BUFFER directions_10 DATA_TYPE uint32 STD430 DATA 0 END
 BUFFER directions_10_index DATA_TYPE uint32 STD430 DATA 0 END

 BUFFER output DATA_TYPE uint32 STD430 SIZE 5 FILL 0
 BUFFER output_index DATA_TYPE uint32 STD430 DATA 0 END

 PIPELINE compute pipeline
   ATTACH compute_shader
   BIND BUFFER directions_10 AS storage DESCRIPTOR_SET 0 BINDING 0
   BIND BUFFER directions_10_index AS storage DESCRIPTOR_SET 0 BINDING 1

   BIND BUFFER output AS storage DESCRIPTOR_SET 0 BINDING 2
   BIND BUFFER output_index AS storage DESCRIPTOR_SET 0 BINDING 3

 END
 RUN pipeline 1 1 1

 EXPECT directions_10 IDX 0 EQ 0
 EXPECT directions_10_index IDX 0 EQ 0
 EXPECT output IDX 0 EQ 8 9 10 13 0
 EXPECT output_index IDX 0 EQ 0
```

The SPIR-V program is embedded within the amber scaffolding. It starts after the line `SHADER compute compute_shader SPIRV-ASM` and ends with `OpFunctionEnd`. The SPIR-V program contains as a comment the path that should be taken by the program, in this case `; unique path #0: 8 -> 9 -> <10> -> 13`. This means that blocks 8, 9, 10 and 13 should be visited in order.

For blocks that unconditionally branch to the next block in the path, it is easy to generate SPIR-V code. Howver, for blocks that end with a conditional branch instruction, we need to force the branch instruction to take the branch required by our expected path. In fact, we would like to be able to choose a different branch on each visit to the block. To accomplish this, for every conditional block, we maintain a directions array where `directions[i]` contains the choice that needs to be made on the ith visit to the block. 

In the example above, there is a single conditional block, block 10, which is indicated by the <> surrounding the block id in the path comment. For block 10, the directions array is called `directions_10`. Since block 10 is only visited once, `directions_10` contains only one entry which is 0. This means that the conditional instruction at the end of block 10:
```
OpBranchConditional %temp_10_6 %11 %13
``` 
will take the branch to `%13` (`directions_10[0]` is loaded into `%temp_10_6`). If the entry was 1, the branch to `%11` would be taken.

To detect miscompilations, we need check to check that blocks were visited in the order we expected. To do this, whenever a block is visited, it records its unique id to the `output` array. The compiler must preserve all writes to this array as it is visible to the host CPU. Therefore, if any values are missing or incorrect, it indicates a miscompilation. The amber code contains an expectation to check that the `output` array matches the expected path, in this case the check is ` EXPECT output IDX 0 EQ 8 9 10 13 0` which asserts that the `output` array should be equal to `[8, 9, 10, 13]`.

### Op-phi instructions
To include op-phi instructions in the fleshed test case, append the --op-phi option. For example:
```
python3 fleshing/fleshout.py fleshing/test_sets/vulkan_cts/xml/s005/test_0.xml --seed 1 --op-phi
```
Op-phi instructions change the way that we maintain the directions index variable for each directions array. The directions index variable is incremented on each visit to a conditional block so that a different choice can be made when it is next visited. By default, we use `OpLoad` and `OpStore` instructions, which are basic load/store instructions. However, since SPIR-V programs are required to be in SSA form, it is easy to replace these load/store instructions with `OpPhi` instructions. To see the difference between a program with and without `OpPhi` instructions, compare the SPIR-V for block 10 in the new program (show below), with the previous program:
```
         %10 = OpLabel ; validCFG/Block$4
  %temp_10_0 = OpPhi %4 %temp_9_2 %9
  %temp_10_3 = OpPhi %4 %9_target_10 %9
  %temp_10_1 = OpAccessChain %storage_buffer_int_ptr %output_variable %constant_0 %temp_10_0
               OpStore %temp_10_1 %constant_10
  %temp_10_2 = OpIAdd %4 %temp_10_0 %constant_1
  %temp_10_4 = OpAccessChain %storage_buffer_int_ptr %directions_10_variable %constant_0 %temp_10_3
  %temp_10_5 = OpLoad %4 %temp_10_4
  %temp_10_6 = OpIEqual %3 %temp_10_5 %constant_1
  %temp_10_7 = OpIAdd %4 %temp_10_3 %constant_1
               OpStore %directions_10_index %temp_10_7
               OpBranchConditional %temp_10_6 %11 %13
```

### Independent Paths
It is possible to have the test case use multiple threads, where each thread will follow an independent path through the control flow graph. Although it is supported, for simplicity we do not use the independent paths option with op-phi instructions. 

In SPIR-V, threads can exist in the x, y and z dimensions of a workgroup, and there can be many workgroups. Similarly, workgroups are organised in the x, y and z dimensions. We provide options to limit the maximum number of threads and workgroups in each dimension as shown below.

To have 2 threads and workgroups in each dimension, run:
```
python3 fleshing/fleshout.py fleshing/test_sets/vulkan_cts/xml/s005/test_0.xml --seed 1 --x-threads 2 --y-threads 2 --z-threads 2 --x-workgroups 2 --y-workgroups 2 --z-workgroups 2
```
This will produce programs with a maximum of 8 threads per workgroup and a maximum of 8 workgroups, giving a total maximum thread count of 64. Since each thread can follow an independent path, there are potentially 64 paths through the control flow graph being explored by this one test case.

If you inspect the SPIR-V generated by the above command, you will notice that there are now two paths listed:
```
; unique path #0: 8 -> 9 -> <10> -> <11> -> <14> -> 15 -> 13
; unique path #1: 8 -> 9 -> <10> -> 13
```
and the program has two threads:
```
OpExecutionMode %7 LocalSize 1 1 2
```
The `LocalSize 1 1 2 ` means that there are two threads (`1 * 1 * 2 = 2`).

### Fleshing runner
We provide a convenience script `fleshing/fleshing_runner.py` that takes in a folder of CFGs represented as XML files and will automatically produce test cases ready for execution. It can be configured to produce multiple different test cases for the same CFG. To produce a single test case for each CFG from the Vulkan CTS, run:
```
python3 fleshing/fleshing_runner.py fleshing/test_sets/vulkan_cts/xml/ --fleshing-seeds 1
```
The `--fleshing-seeds 1` option ensures each test case is produced with the seed 1. To create more test cases for each CFG, add more seeds, for example, `--fleshing-seeds 1 2 3` will produce three three test cases per CFG. If you don't care about the seeds used, you can simply pass the `--repeats X` flag, which will create `X` test cases for each CFG. 

You can pass the same commands to the `fleshing_runner.py` as passed to `fleshout.py` earlier e.g. you can append `--op-phi` to enable op-phi instructions.

Running the command above should only take a few seconds as the fleshing process is fast. You should see `Produced 391 amber files from 392 xml files` towards the bottom of the output. One XML file is skipped because the CFG either has no exit nodes or none are reachable from the entry point of the SPIR-V program. All test cases are written in the same directory as the corresponding XML file.

### Executing fleshed test cases
To execute a single fleshed test case, you can invoke amber directly as:
```
/data/git/amber/out/Debug/amber <path to amber file>
```
For the Vulkan CTS example, you can run:
```
/data/git/amber/out/Debug/amber fleshing/test_sets/vulkan_cts/xml/s005/test_0_1.amber
```
which will output:
```
Summary: 1 pass, 0 fail
```
To indicate that the test case executed successfully. 
We provide a program `fleshing/amber_runner.py` (amber runner) that will run all amber files within a directory, as well as keeping track of the results in a convenient manner. To run it:
```
python3 fleshing/amber_runner.py </path/to/directory/containing/amber/files> <path/to/amber> 
```
In this case:
```
python3 fleshing/amber_runner.py fleshing/test_sets/vulkan_cts/xml/ /data/git/amber/out/Debug/amber 
```

As the above command executes, it will print the current amber file that is being executed along with a count of how many amber files have been executed so far, for example:
```
Execution count 134. Executing fleshing/test_sets/vulkan_cts/xml/s155/test_0_1.amber
```
If there are any errors, they will be printed to the console. A log file is also generated, which can be accessed in the ./logs directory, and will be called amber_runner_\<timestamp\>.log.

As we used the seed 1 during the fleshing process, the results are deterministic and you should see that there are no errors found. This will be indicated by the final line in the output:
```
0 errors found during execution.
```

## Finding compiler bugs using fleshing (Claim 9)
We will demonstrate three bugs that we found in the Google SwiftShader driver (the full list of bugs can be found in Bugs.ods). We use SwiftShader because it requires no GPU hardware (it runs on the CPU) and it is relatively fast to execute test cases. Run all commands from the `/data/git/spirv-control-flow` directory. 

1. The first bug found is a segfault (crash bug). The bug report is [here](https://issuetracker.google.com/issues/228985910). To trigger this bug, run the following:
```
/data/git/amber/out/Debug/amber fleshing/examples/bugs/reduced-segfault.amber
```
You should see the output `Segmentation fault (core dumped)`.

2. The second bug found is an infinite loop bug. The bug report is [here](https://issuetracker.google.com/issues/228512142). To trigger this bug, run the following:
```
/data/git/amber/out/Debug/amber fleshing/examples/bugs/reduced-infinite-loop.amber
```
You should see that the program hangs. Depending on your exact settings, it may eventually crash with a timeout.

3. The third bug found is a miscompilation bug. The bug report is [here](https://issuetracker.google.com/issues/229123528). To trigger this bug, run the following:
```
/data/git/amber/out/Debug/amber fleshing/examples/bugs/reduced-output-oracle.amber 
```
The output should contain the following:
```
fleshing/examples/bugs/reduced-output-oracle.amber: Line 119: Verifier failed: 0 == 8, at index 0
```
This output indicates a miscompilation bug. In other words, the compiler in the SwiftShader driver did not crash, but instead produced incorrect code. Our oracle expects a particular path to be taken and when that path is not taken, we know there is a miscompilation bug. In this case, the expectation was that block 8 should have been visited first (this is the entry block to the program). However, nothing was written to the output array to record this (the output array is initialized with zeros). This indicates that there is a miscompilation bug, as the compiler in the driver must preserve writes to the output array.

### Test Sets:
Below, we list all of the test sets used in the paper. For the purpose of checking this example, you only need to download `Tests-Basic-Alloy.tar.gz`. You can download and run the other test sets, but be warned that some are quite large.
1. Tests-Basic-CTS.tar.gz: The "Basic CTS" set (Table 1)
2. Tests-Basic-Alloy.tar.gz: The "Basic Alloy" set (Table 1)
3. Tests-Phi-CTS.tar.gz: The "Phi CTS" set (Table 1)
4. Tests-Phi-Alloy.tar.gz: The "Phi Alloy" set (Table 1)
5. Tests-Throughput.tar.gz: The tests used for throughput testing (Table 3). Warning, this will take somewhere between 10 and 39 hours to run.

The test sets above can all be downloaded and copied to the docker container. To copy them, run the following:
```
docker cp /path/to/downloaded/test/cases <docker container id>:/desired/location/in/docker/container 
```
To find the container id, run `docker ps`. You can execute the test cases using the amber runner as normal. For example, to execute Tests-Basic-Alloy, which was able to find 3 distinct bugs in SwiftShader, run:
```
python3 fleshing/amber_runner.py /desired/location/in/docker/container /data/git/amber/out/Debug/amber
```
This test set has roughly 23,000 test cases and take about 20 mins to run.
